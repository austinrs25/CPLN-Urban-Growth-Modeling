---
title: "Urban Growth Forecast: Charlotte, NC (CPLN 6750 Final Project, Spring 2025)"
author: "Abe Doroshow & Austin Studner-Sutherland"
date: "5/10/2025"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

<style>
  .superbigimage{
      overflow-x:scroll;
      white-space: nowrap;
  }

  .superbigimage img{
     max-width: none;
  }


</style>

# 1. Introduction and Planning Rationale

This analysis adopts a reduced-form urban growth modeling approach, inspired by the California Urban Futures Model and adapted through the lens of CPLN 6750. We forecast development in the Charlotte MSA using a logistic regression model trained on raster data. Our goal is to understand the influence of infrastructural accessibility, land cover, and population dynamics on the spatial distribution of future development. We hypothesize that development occurs where higher and better land use is expected to yield returns, moderated by factors like proximity to infrastructure and population pressures.

Charlotte, North Carolina, is one of the fastest-growing metro areas in the southeastern United States. Its population grew by 35.2% from 2000 to 2010, 19.6% from 2010 to 2020, and is forecasted to grow an additional 14.1% from 2020 to 2030. This project aims to forecast urban development in the Charlotte Metropolitan Area, specifically Mecklenburg, Cabarrus, Gaston, and Union counties, by the year 2031. **This scenario includes a proposed new highway running from southeastern Mecklenburg into downtown Charlotte, designed to increase connectivity and redirect growth pressure.**


# 2. Analytical Workflow

This workflow closely mirrors the original instructional steps and includes:

1. **Data Import**: Land cover data for 2011 (t1) and 2019 (t2) are loaded and reclassified to identify developed/undeveloped areas.
2. **Resampling**: The raster data are resampled to a lower resolution to optimize computation.
3. **Land Cover Change Detection**: Using map algebra, we identify grid cells that transitioned from undeveloped to developed.
4. **Fishnet Creation**: A uniform spatial grid (fishnet) overlays the study area for tabular modeling.
5. **Feature Engineering**: Variables include land cover type, population density (via areal weighted interpolation), distance to highways, spatial lag of development, and proximity to planned infrastructure.
6. **Data Integration**: Variables are spatially joined to the fishnet and prepared for modeling.
7. **Exploratory Analysis**: Visualization of features to examine their distribution and potential relationship to development.
8. **Modeling**: A binomial logistic regression is trained to predict land cover change between t1 and t2.
9. **Validation**: Model is validated using a test set, ROC curve, and confusion matrix. Classification thresholds are tested for generalizability.
10. **Forecasting**: t2 data (plus new infrastructure) are input to the model to generate a 2027 (t3) development forecast.
11. **Impact Assessment**: Predicted changes are analyzed in aggregate and by subregion and land type.
12. **Planning Recommendations**: Based on outputs, strategies are proposed to align infrastructure, zoning, and conservation policies.


# 3. Feature Engineering

We assume a new primairy highway is introduced in southeast Mecklenburg County to enhance commuting access and connection to the city. This infrastructure investment is expected to increase the likelihood of development in surrounding areas. Distance to this corridor is incorporated as a predictor variable in both the t2 model and the t3 forecast.

## 3.1. Setup Libraries, Functions, and Color Pallette

**Load Libraries and Color Pallette:**

```{r load_packages, message=FALSE, warning=FALSE, results = "hide"}
library(tidyverse)
library(sf)
library(raster)
library(kableExtra)
library(tidycensus)
library(tigris)
library(FNN)
library(caret)
library(yardstick)
library(plotROC) 
library(ggrepel)
library(pROC)
library(grid)
library(gridExtra)
library(viridis)
library(igraph)
library(mapview)
library(FedData)

palette2 <- c("#41b6c4","#253494")
palette4 <- c("#a1dab4","#41b6c4","#2c7fb8","#253494")
palette5 <- c("#ffffcc","#a1dab4","#41b6c4","#2c7fb8","#253494")
palette10 <- c("#f7fcf0","#e0f3db","#ccebc5","#a8ddb5","#7bccc4",
               "#4eb3d3","#2b8cbe","#0868ac","#084081","#f7fcf0")
```

**Load functions:** 

```{r, warning = FALSE, message = FALSE}
#this function converts a column in to quintiles. It is used for mapping.
quintileBreaks <- function(df,variable) {
    as.character(quantile(df[[variable]],
                          c(.01,.2,.4,.6,.8),na.rm=T))
}

#This function can be used to convert a polygon sf to centroids xy coords.
xyC <- function(aPolygonSF) {
  as.data.frame(
    cbind(x=st_coordinates(st_centroid(aPolygonSF))[,1],
          y=st_coordinates(st_centroid(aPolygonSF))[,2]))
} 

#this function convert a raster to a data frame so it can be plotted in ggplot
rast <- function(inRaster) {
  data.frame(
    xyFromCell(inRaster, 1:ncell(inRaster)), 
    value = getValues(inRaster)) }

# knn distance function

nn_function <- function(measureFrom,measureTo,k) {
  #convert the sf layers to matrices
  measureFrom_Matrix <-
    as.matrix(measureFrom)
  measureTo_Matrix <-
    as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
    output <-
    as.data.frame(nn) %>%
    rownames_to_column(var = "thisPoint") %>%
    gather(points, point_distance, V1:ncol(.)) %>%
    arrange(as.numeric(thisPoint)) %>%
    group_by(thisPoint) %>%
    summarize(pointDistance = mean(point_distance)) %>%
    arrange(as.numeric(thisPoint)) %>% 
    dplyr::select(-thisPoint) %>%
    pull()
  
  return(output)  
}

aggregateRaster <- function(inputRasterList, theFishnet) {
  #create an empty fishnet with the same dimensions as the input fishnet
  theseFishnets <- theFishnet %>% dplyr::select()
  #for each raster in the raster list
  for (i in inputRasterList) {
  #create a variable name corresponding to the ith raster
  varName <- names(i)
  #convert raster to points as an sf
    thesePoints <-
      rasterToPoints(i) %>%
      as.data.frame() %>%
      st_as_sf(coords = c("x", "y"), crs = st_crs(theFishnet)) %>%
      filter(.[[1]] == 1)
  #aggregate to the fishnet
    thisFishnet <-
      aggregate(thesePoints, theFishnet, length) %>%
      mutate(!!varName := ifelse(is.na(.[[1]]),0,1))
  #add to the larger fishnet
    theseFishnets <- cbind(theseFishnets,thisFishnet)
  }
  #output all aggregates as one large fishnet
   return(theseFishnets)
  }
```

## 3.2. Setup the Study Area

A shapefile for the study area was engineered in ArcGIS Pro and exported to a GeoJSON and stored in Github for this analysis. 

**Load Administrative Boundaries and Set Coordinate Reference System (CRS):**

```{r}
charlotteMSA <- 
  st_read("https://raw.githubusercontent.com/austinrs25/CPLN-Urban-Growth-Modeling/refs/heads/main/charlotteMSA.geojson") 
charlotteMSA %>% st_transform(2264)

```
## 3.3. Land Cover Analysis and Workflow

To detect land use change between 2011 (t1) and 2019 (t2), we begin by analyzing land cover rasters for the Charlotte MSA. These rasters are processed to highlight locations where land converted from undeveloped to developed. This binary change variable becomes the dependent variable in our logistic regression model.

**Load 2011 Land Cover Data and Clip Raster to Study Area:**

```{r}

lc_2011 <- get_nlcd(
    template = charlotteMSA,
    label = "lc_2011",
    year = 2011
  ) %>%
  raster(.)

```

**Load 2019 Land Cover Data and Clip Raster to Study Area:**
```{r}

lc_2019 <- get_nlcd(
    template = charlotteMSA,
    label = "lc_2019",
    year = 2019
  ) %>%
  raster(.)

```

**Resample Rasters:**

Given the high resolution of NLCD rasters (30 meters), we resample them to coarser grids to improve processing speed and reduce memory demands during modeling. We use the `aggregate` function from the `raster` package with the `modal` function to summarize land cover within larger cells, preserving the dominant land type.

```{r}
lc_2011_rs <- aggregate(lc_2011, fact = 30, fun = "modal")

lc_2019_rs <- aggregate(lc_2019, fact = 30, fun = "modal")

```

**Reclassify Land Cover as Developend and Undeveloped:**

We reclassify the resampled rasters into two categories: developed (NLCD codes 21â€“24) and undeveloped (all other codes). This results in a simplified binary classification of each cell for both t1 and t2. 

```{r}
reclassMatrix <- 
  matrix(c(
    0,12,0,
    12,24,1,
    24,Inf,0),
  ncol=3, byrow=T)
```

```{r, warning = FALSE, message = FALSE}
developed_2011 <- 
  reclassify(lc_2011_rs, reclassMatrix)

developed_2019 <- 
  reclassify(lc_2019_rs, reclassMatrix)

```

**Detect Change from 2011 (t1) to 2018 (t2):**

Change is then detected using map algebra, identifying cells that were undeveloped in t1 and developed in t2. Cells with no change are assigned NA, allowing us to focus modeling efforts on the subset of cells where development did occur.

```{r, warning = FALSE, message = FALSE}

development_change <- developed_2011 + developed_2019

```

**Visualize Development Change:**

We use the `mapview` package to visualize the resulting change raster interactively. This allows for quick inspection of spatial development patterns and supports verification of our reclassification and change detection steps.

Create histogram to illustrate frequency of conversion from undeveloped to developed between 2011 and 2019 where the 1's represent change. O's and 2's represent no change where 0's demarcate land being undeveloped in both periods and 2 demarcate land be developed in both periods - this presumes no land when from developed to undeveloped.

```{r, warning = FALSE, message = FALSE}
hist(development_change)
```

Create a map from raster to illustrate land cover change, first removing 0's (undeveloped lands) and 2's (developed lands), where 1's represent change (from undeveloped to devloped):

```{r, warning = FALSE, message = FALSE}
development_change[development_change != 1] <- NA
```

```{r}
mapView(development_change)

```

## 3.4. Engineering the Fishnet

**Create Fishnet:**

To facilitate modeling and analysis at a consistent spatial scale, we convert raster data to a regular vector grid, commonly referred to as a fishnet. Each cell in this fishnet becomes a unit of observation, with associated attributes describing land cover and other predictors.

```{r, warning = FALSE, message = FALSE}
charlotteMSA_fishnet <- 
  st_make_grid(charlotteMSA %>%
                     st_transform(crs(development_change)),
                 cellsize = res(development_change)[1], 
                 square = TRUE) %>% 
  st_sf() %>% 
  st_intersection(., charlotteMSA %>%
                    dplyr::select(geometry) %>%
                         st_transform(crs(development_change))) %>%
  mutate(uniqueID = rownames(.))
```

**Aggregate Land Cover Change to the Fishnet:**

First, we convert our binary land cover change raster (indicating development from 2011 to 2019) into points. These are then spatially aggregated to our Charlotte MSA fishnet grid. Each grid cell is assigned a value of 1 if development occurred within its bounds, and 0 otherwise. This step transforms spatially continuous raster data into a tabular form suitable for logistic regression.

```{r}
changePoints <-
  rasterToPoints(development_change) %>%
  as.data.frame() %>%
  st_as_sf(coords = c("x", "y"), 
           crs = st_crs(charlotteMSA_fishnet))

fishnet <- 
  aggregate(changePoints, 
            charlotteMSA_fishnet, 
            FUN=sum) %>%
  mutate(development_change = ifelse(is.na(layer) == TRUE , 0, 1),
         development_change = as.factor(development_change)) %>%
  dplyr::select(-layer)

```

A quick map shows development change across the region. By plotting fishnet cell centroids and coloring them by their change status, we visually confirm where growth has occurred over the decade.

```{r}
ggplot() +
  geom_sf(data=charlotteMSA %>% 
            st_transform(crs(fishnet))) +
  geom_point(data=fishnet, 
             aes(x=xyC(fishnet)$x, 
                 y=xyC(fishnet)$y, 
                 colour=development_change)) +
  scale_colour_manual(values = palette2,
                      labels=c("No Change","New Development"),
                      name = "") +
  labs(title = "Land Cover Development Change", subtitle = "As fishnet centroids") +
  theme_void()
```

**Reclassify and Aggregate Batch Land Cover Data to the Fishnet:**

To enhance model accuracy, we reclassify the full land cover dataset into broader land use categories: developed, forest, farm, wetlands, other undeveloped, and water. This simplification improves interpretability and reduces data sparsity.

| Old_Classification | New_Classification |
|------------------------------------------------------------------|-------------------|
| Open Space as well as Low, Medium and High Intensity Development | Developed |
| Deciduous, Evergreen, and Mixed Forest |  Forest |
| Pasture/Hay and Cultivated Crops | Farm |
| Woody and Emergent Herbaceous Wetlands | Woodlands |
| Barren Land, Dwarf Scrub, and Grassland/Herbaceous | Other Undeveloped |
| Water | Water |

Create New Classification Rasters:
```{r, warning = FALSE, message = FALSE}

developed_2011 <- lc_2011_rs  %in% c(21, 22, 23, 24)
forest_2011 <- lc_2011_rs %in% c(41, 42, 42)
farm_2011 <- lc_2011_rs %in% c(81, 82)
wetlands_2011 <- lc_2011_rs %in% c(90, 95) 
otherUndeveloped_2011 <- lc_2011_rs %in% c(52, 71, 31)
water_2011 <- lc_2011_rs == 11

developed_2019 <- lc_2019_rs %in% c(21, 22, 23, 24)
forest_2019 <- lc_2019_rs %in% c(41, 42, 42)
farm_2019 <- lc_2019_rs %in% c(81, 82)
wetlands_2019 <- lc_2019_rs %in% c(90, 95) 
otherUndeveloped_2019 <- lc_2019_rs %in% c(52, 71, 31)
water_2019 <- lc_2019_rs == 11
```

For both t1 (2011) and t2 (2018), we construct binary raster layers representing the presence of each land use type. These rasters are named accordingly and compiled into lists.

```{r, warning = FALSE, message = FALSE}

names(developed_2011) <- "developed_2011"
names(forest_2011) <- "forest_2011"
names(farm_2011) <- "farm_2011"
names(wetlands_2011) <- "wetlands_2011"
names(otherUndeveloped_2011) <- "otherUndeveloped_2011"
names(water_2011) <- "water_2011"

names(developed_2019) <- "developed_2019"
names(forest_2019) <- "forest_2019"
names(farm_2019) <- "farm_2019"
names(wetlands_2019) <- "wetlands_2019"
names(otherUndeveloped_2019) <- "otherUndeveloped_2019"
names(water_2019) <- "water_2019"
```


```{r, warning = FALSE, message = FALSE}
rasterList_2011 <- c(developed_2011,
                   forest_2011,
                   farm_2011,
                   wetlands_2011,
                   otherUndeveloped_2011,
                   water_2011)

rasterList_2019 <- c(developed_2019,
                   forest_2019,
                   farm_2019,
                   wetlands_2019,
                   otherUndeveloped_2019,
                   water_2019)
```

Using a batch aggregation function (`aggregateRaster`), we spatially join these raster layers to the fishnet. The result is a dataset where each cell is tagged with binary indicators for each land cover category. This process ensures our model includes rich information about the land characteristics of each grid cell at both time points.

```{r, warning = FALSE, message = FALSE}
lcRasters_2011 <-
  aggregateRaster(rasterList_2011, 
                  charlotteMSA_fishnet) %>%
  dplyr::select(developed_2011,
                   forest_2011,
                   farm_2011,
                   wetlands_2011,
                   otherUndeveloped_2011,
                   water_2011) %>%
  mutate_if(is.numeric,as.factor)

lcRasters_2019 <-
  aggregateRaster(rasterList_2019, 
                  charlotteMSA_fishnet) %>%
  dplyr::select(developed_2019,
                   forest_2019,
                   farm_2019,
                   wetlands_2019,
                   otherUndeveloped_2019,
                   water_2019) %>%
  mutate_if(is.numeric,as.factor)

```

Visualization of the aggregated layers confirms successful mapping. Faceted maps by land cover type show the spatial distribution of different land uses in 2011, helping validate classification and detect emerging development patterns.

```{r, message = FALSE, warning = FALSE}
lcRasters_2011 %>%
  st_centroid() %>%
 gather(key = "variable", value = "value", developed_2011:water_2011) %>% 
  mutate(X = xyC(.)$x,
         Y = xyC(.)$y) %>%
  ggplot() +
    geom_sf(data=charlotteMSA) +
    geom_point(aes(X,Y, colour=as.factor(value))) +
    facet_wrap(~variable) +
    scale_colour_manual(values = palette2,
                        labels=c("Other","Land Cover"),
                        name = "") +
    labs(title = "Land Cover Types, 2011",
         subtitle = "As fishnet centroids") +
   theme_void()
```





**Import Census Data and Joining to the Fishnet:**

Population density serves as a critical demand-side factor in forecasting urban growth. In this analysis, we retrieved total population data for 2011 (t1) and 2019 (t2) using the `tidycensus` package. Since the census data are aggregated at the tract level, we implemented a technique known as areal weighted interpolation (AWI) to align this data with our fishnet grid.

AWI apportions tract-level population values to fishnet cells based on the proportion of spatial overlap, providing a refined spatial approximation of population distribution. This step ensures each fishnet cell has a representative population estimate for both t1 and t2, enabling our model to capture population-driven development patterns.

**Downloading and Tidying Census Data:**

We use the Census API to extract population data for the counties in the Charlotte MSA: Mecklenburg, Cabarrus, Gaston, and Union. Each dataset is transformed into the same CRS as the fishnet and lightly buffered to avoid geometry issues during spatial processing.

Load Census Data:
```{r load_key, warning = FALSE, eval = FALSE}
census_api_key("e79f3706b6d61249968c6ce88794f6f556e5bf3d", overwrite = TRUE)
```

Pull population data for `t1` (2011) and reproject to CRS:
```{r, warning = FALSE, message = FALSE, results = "hide"}
# Specify which variable(s) you would like to grab. Here, only one (Total Population) is listed, but you could add more to the call.
acs_vars <- c("B02001_001E")

# Using "tract" as the geography and 2011 as the year, download data data for the Charlotte MSA counties listed.
charlottePop11 <- get_acs(geography = "tract", 
                        variables = acs_vars, 
                        year = 2011,
                        state = 37, 
                        geometry = TRUE, 
                        output = "wide",
                        county=c("Mecklenburg", "Cabarrus", "Gaston", "Union")) %>%
                dplyr::select (GEOID, NAME, acs_vars) %>%
                rename(pop_2011 = B02001_001E) %>%
                st_transform(st_crs(charlotteMSA_fishnet)) %>%
                st_buffer(-1)
```

Pull population data for `t2` (2019) and reproject to CRS:
```{r, warning = FALSE, message = FALSE, results = "hide"}
# Specify which variable(s) you would like to grab. Here, only one (Total Population) is listed, but you could add more to the call.
acs_vars <- c("B02001_001E")

# Using "tract" as the geography and 2019 as the year, download data data for the Charlotte MSA counties listed.
charlottePop19 <- get_acs(geography = "tract", 
                        variables = acs_vars, 
                        year = 2019,
                        state = 37, 
                        geometry = TRUE, 
                        output = "wide",
                        county=c("Mecklenburg", "Cabarrus", "Gaston", "Union")) %>%
                dplyr::select (GEOID, NAME, acs_vars) %>%
                rename(pop_2019 = B02001_001E) %>%
                st_transform(st_crs(charlotteMSA_fishnet)) %>%
                st_buffer(-1)
```

**Create choropleth maps** to show total population distributed by quintiles, comparing population density in both years (2011 and 2019). This upward shift in population desnsity reflects the Charlotte MSAâ€™s ongoing urbanization, particularly within Mecklenburg County and along key suburban corridors.

<div class="superbigimage"> 
```{r, warning = FALSE, message = FALSE, fig.height= 8, fig.width= 11}
grid.arrange(
ggplot() +
  geom_sf(data = charlottePop11, aes(fill=factor(ntile(pop_2011,5))), colour=NA) +
  scale_fill_manual(values = palette5,
                    labels=quintileBreaks(charlottePop11,"pop_2011"),
                   name="Quintile\nBreaks") +
  labs(title="Population, Charlotte MSA: 2011") +
  theme_void(),

ggplot() +
  geom_sf(data = charlottePop19, aes(fill=factor(ntile(pop_2019,5))), colour=NA) +
  scale_fill_manual(values = palette5,
                    labels=quintileBreaks(charlottePop19,"pop_2019"),
                   name="Quintile\nBreaks") +
  labs(title="Population, Charlotte MSA: 2019") +
  theme_void(), ncol=2)
```
</div>


**Perform Areal Weighted Interpolation (AWI):**

We perform AWI for both 2011 (t1) and 2019 (t2), creating population estimates for each grid cell. These interpolated values are joined back to the fishnet, resulting in spatially consistent population features named `pop_2011` and `pop_2019`.

Perform AWI for `t1` (2011):
```{r, warning = FALSE, message = FALSE}
pop_interp <- st_interpolate_aw(charlottePop11["pop_2011"], 
                                 charlotteMSA_fishnet, 
                                 extensive = TRUE)

pop_vec <- rep(NA_real_, nrow(charlotteMSA_fishnet))
pop_vec[match(st_geometry(pop_interp), st_geometry(charlotteMSA_fishnet))] <- pop_interp$pop_2011

fishnetPopulation11 <- charlotteMSA_fishnet %>%
  mutate(pop_2011 = replace_na(pop_vec, 0))
```

Perform AWI for `t2` (2019):
```{r}
pop_interp <- st_interpolate_aw(charlottePop19["pop_2019"], 
                                 charlotteMSA_fishnet, 
                                 extensive = TRUE)

pop_vec <- rep(NA_real_, nrow(charlotteMSA_fishnet))
pop_vec[match(st_geometry(pop_interp), st_geometry(charlotteMSA_fishnet))] <- pop_interp$pop_2019

fishnetPopulation19 <- charlotteMSA_fishnet %>%
  mutate(pop_2019 = replace_na(pop_vec, 0))
```

This transformation addresses the Modifiable Areal Unit Problem (MAUP) inherent in tract-level data and enhances the spatial resolution of our model inputs. When visualized, these population layers reveal spatial densification patterns across the Charlotte region, with a clear concentration of growth in urban and near-suburban areas.

**Map AWI Transformations:**
<div class="superbigimage"> 
```{r, warning = FALSE, message = FALSE, fig.height = 8, fig.width= 11}
grid.arrange(
ggplot() +
  geom_sf(data=charlottePop11, aes(fill=factor(ntile(pop_2011,5))),colour=NA) +
  scale_fill_manual(values = palette5,
                    labels=substr(quintileBreaks(charlottePop11,"pop_2011"),1,4),
                   name="Quintile\nBreaks") +
  labs(title="Population, Charlotte MSA: 2011",
       subtitle="Represented as tracts; Boundaries omitted") +
  theme_void(),

  ggplot() +
  geom_sf(data=fishnetPopulation11, 
         aes(fill=factor(ntile(pop_2011,5))),colour=NA) +
  scale_fill_manual(values = palette5,
                   labels=substr(quintileBreaks(fishnetPopulation11,"pop_2011"),1,4),
                   name="Quintile\nBreaks") +
  labs(title="Population, Charlotte MSA: 2011",
       subtitle="Represented as fishnet gridcells; Boundaries omitted") +
  theme_void(), ncol=2)
```
</div>



**Import Transportation and Infrastructure:**

Accessibility plays a critical role in shaping urban development. In this section, we evaluate proximity to highway infrastructure across the Charlotte MSA, based on the hypothesis that areas nearer to highways are more likely to urbanize. This is grounded in the traditional **bid-rent theory** of land use, proximity to Central Business Districts (CBDs), linking accessibility with land value and density of development.

To operationalize this, we calculate the Euclidean distance from each fishnet centroid to the nearest highway segment. This continuous variable serves as a proxy for transportation accessibility and is included as a predictor in our logistic regression model.

**Highway Data Acquisition and Visualization:**

Using the `Tigris` package, we download primary and secondary road geometries for North Carolina, clip them to the Charlotte MSA, and project them into our analysis CRS.

Import Highways Data and Project to CRS:
```{r, warning = FALSE, message = FALSE, results = "hide"}
charlotteHighways <-
  tigris::primary_secondary_roads(state = "NC") %>%
  st_transform(st_crs(charlotteMSA)) %>%
  st_intersection(charlotteMSA) %>%
  st_transform(st_crs(fishnet))
```

A **preliminary map** overlays these highways on top of development change data, providing visual evidence of possible spatial correlation between highway access and urban expansion:
```{r plot_highway, warning = FALSE, message= FALSE}
ggplot() +
  geom_point(data=fishnet, 
             aes(x=xyC(fishnet)[,1], y=xyC(fishnet)[,2],colour=development_change),size=1.5) +
  geom_sf(data=charlotteHighways) +
  scale_colour_manual(values = palette2,
                      labels=c("No Change","New Development")) +
  labs(title = "New Development and Highways",
       subtitle = "As fishnet centroids") +
  theme_void()
```




# ALERT  ------- I BELIEVE THIS STEP (CODE AND NARRATIVE TEXT) WILL NEED TO BE ADJUSTED TO INCLUDE NEW HIGHWAY FOR T3 FORECAST  -- **REFERENCE 7.2 IN MICHAEL'S RMD** -- CREATE A BEFORE AND AFTER, SO LIKELY COPY AND PASTE AND ONLY ADJUST THE PASTED CODE SO THE CURRENT CODE CAN STAY AND REPRESENT THE BEFORE AND YOUR PASTED AND THEN EDITED CODE WILL REPRESENT THE AFTER  ------- 



**Calculate Distance to Highways:**

We compute a new variable, `distance_highways_2011`, for each fishnet cell by measuring the straight-line distance to the nearest highway feature. This step uses `st_distance` and applies to centroid points derived from the fishnet. These distances are added back to the fishnet, enabling their use in modeling and spatial analysis.

To maintain modeling consistency, we mirror this step for `t2`, creating `distance_highways_2019`. **If simulating the effect of proposed infrastructure, such as a future highway or transit line, a modified distance layer would be introduced here to inform the `t3` forecast.**

```{r, warning = FALSE, message = FALSE}
highwayPoints_fishnet_2011 <- charlotteMSA_fishnet %>%
  st_centroid() %>%
  mutate(distance_highways_2011 = as.numeric(st_distance(., st_union(charlotteHighways) %>% 
                                                      st_transform(st_crs(charlotteMSA_fishnet))))) %>%
  as.data.frame() %>% 
  dplyr::select(-geometry) %>% 
  left_join(charlotteMSA_fishnet, .) %>% 
  st_as_sf()

highwayPoints_fishnet_2019 <- highwayPoints_fishnet_2011 %>%
  rename(distance_highways_2019 = distance_highways_2011)

```

This **map displays distance-to-highway** values using quintile symbology, visually reinforcing the accessibility gradient across the study area and confirming the spatial precision of this feature.

```{r, warning = FALSE, message = FALSE}

ggplot() +
  geom_sf(data=charlotteMSA %>% st_transform(st_crs(highwayPoints_fishnet_2011))) +
  geom_point(data=highwayPoints_fishnet_2011, aes(x=xyC(highwayPoints_fishnet_2011)[,1], 
                                             y=xyC(highwayPoints_fishnet_2011)[,2], 
                 colour=factor(ntile(distance_highways_2011,5))),size=1.5) +
  scale_colour_manual(values = palette5,
                      labels=substr(quintileBreaks(highwayPoints_fishnet_2011,"distance_highways_2011"),1,8),
                      name="Quintile\nBreaks") +
  geom_sf(data=charlotteHighways, colour = "red") +
  labs(title = "Distance to Highways (m)",
       subtitle = "As fishnet centroids; Highways visualized in red") +
  theme_void()
```


# ALERT ------- REMOVE THIS LINE AND MY COMMENT LINE WHEN COMPLETE ------- 





**Calculate Spatial Lag of Development:**

Assuming that proximity to existing development influences the likelihood of future development, as proposed by Prof. Ken Steif, we compute a spatial lag variable to quantify this relationship. Specifically, we calculate the average distance from each fishnet centroid to its two nearest developed neighbors as of 2011 and 2019.

This spatial lag captures local patterns of development clustering and spatial diffusion, serving as a proxy for market signaling and development spillovers. To perform this calculation, we use a custom k-nearest neighbors function (`nn_function`). The inputs are coordinate data for all fishnet centroids and a filtered subset of centroids corresponding to developed cells in each respective year.

Setting `k = 2` reflects an assumption about the local scale of development influence. Adjusting `k` would modify the sensitivity of this variable to spatial context meaning larger `k` values could capture broader neighborhood effects.

Calculate:
```{r, warning = FALSE, message = FALSE}
fishnet$lagDevelopment_2011 <-
    nn_function(fishnet %>%
                  st_centroid() %>%
                  st_coordinates() %>%
                  as.data.frame(),
                lcRasters_2011 %>%
                  filter(developed_2011 == 1) %>%
                  st_centroid() %>%
                  st_coordinates() %>%
                  as.data.frame(),
                2)

fishnet$lagDevelopment_2019 <-
    nn_function(fishnet %>%
                  st_centroid() %>%
                  st_coordinates() %>%
                  as.data.frame(),
                lcRasters_2019 %>%
                  filter(developed_2019 == 1) %>%
                  st_centroid() %>%
                  st_coordinates() %>%
                  as.data.frame(),
                2)
```

The output of this step, `lagDevelopment_2011` and `lagDevelopment_2019`, is a continuous predictor incorporated into our model. A **quintile map of 2011 values illustrates spatial heterogeneity in accessibility to development, confirming the relevance of spatial structure in shaping land use change**:

Visualize Calculation:
```{r, warning = FALSE, message = FALSE}
ggplot() +
  geom_sf(data=charlotteMSA %>% st_transform(st_crs(fishnet))) +
  geom_point(data=fishnet, 
             aes(x=xyC(fishnet)[,1], y=xyC(fishnet)[,2], 
                 colour=factor(ntile(lagDevelopment_2011,5))), size=1.5) +
  scale_colour_manual(values = palette5,
                     labels=substr(quintileBreaks(fishnet,"lagDevelopment_2011"),1,7),
                     name="Quintile\nBreaks") +
  labs(title = "Spatial Lag to 2011 Development, m",
       subtitle = "As fishnet centroids") +
  theme_void()
```


**Import Political Boundaries:**

Incorporating political boundaries, specifically, county-level delineations, into our urban growth model enhances both its interpretability and analytical depth. First, county membership can serve as a fixed effect, capturing regulatory, socio-economic, or cultural factors that may influence development patterns but are not directly observed in other variables. For example, zoning stringency or land use incentives might differ between Mecklenburg and Union counties.

Second, appending county data to the fishnet grid enables spatial disaggregation of model outputs and errors. This supports localized policy recommendations and assessment of the forecastâ€™s implications at the county scale.

To do this, we download county administrative boundaries from the U.S. Census Bureau using the `tigris` package, transform it to the correct CRS, and filter for the four counties comprising the Charlotte MSA: Mecklenburg, Cabarrus, Gaston, and Union. These polygons are spatially joined to the fishnet, assigning each cell a `county` identifier that we include as a fixed effect in our modeling process.

This integration provides a spatial administrative lens through which to interpret both development probabilities and potential policy responses.

```{r, warning = FALSE, message = FALSE, results = "hide"}
options(tigris_class = "sf")

counties <- counties(state = "NC") %>%
  st_as_sf() %>%
  st_transform(st_crs(charlotteMSA_fishnet))

studyAreaCounties <- counties %>%
  filter(NAME %in% c("Mecklenburg", "Cabarrus", "Gaston", "Union"))

```

```{r}
countyFishnet <- charlotteMSA_fishnet %>%
  st_join(., studyAreaCounties %>%
            dplyr::select(NAME)) %>%
  as.data.frame() %>% 
  dplyr::select(uniqueID, NAME) %>% 
  left_join(charlotteMSA_fishnet, .) %>% 
  st_as_sf() %>%
  group_by(uniqueID) %>%
  slice(1) %>%
  ungroup() %>%
  arrange(as.numeric(uniqueID))
  
```


# 4. Exploratory Analysis

## 4.1 Transform Data Set for Modeling

After extensive preprocessing, we consolidate our engineered features into two final datasets: one for model training (based on t1 data) and one for forecasting (based on t2 data). This step brings together all componentsâ€”spatial lag, population, infrastructure (highways), land cover, and county identifiers, into unified spatial tabular data.

Each dataset consists of a shared fishnet structure and includes identical columns, ensuring compatibility with our logistic regression model, as the model can only make predictions on new data that conform to the format it was trained on. For `dat_2011`, we retain variables from 2011 and rename them generically to allow seamless application of the model to `dat_2019`, which mirrors the nomenclature/structure but contains updated predictor values.

To finalize the dataset, we `cbind` together the component data frames (each representing a set of attributes like accessibility, census, or land cover) and filter out cells classified as water. We use `rename_with` to drop the year suffixes and standardize variable names across time points.

This modeling dataset forms the analytical core of our project, from which we explore relationships, validate forecasting/predictive accuracy, and generate the 2027 development forecast.

```{r}


dat_2011 <- 
  cbind( fishnet, highwayPoints_fishnet_2011, fishnetPopulation11, lcRasters_2011, countyFishnet) %>%
  as.data.frame() %>%
  dplyr::select(uniqueID, development_change, lagDevelopment_2011, distance_highways_2011, pop_2011,  
                developed_2011, forest_2011, farm_2011, wetlands_2011, otherUndeveloped_2011, water_2011,
                NAME, geometry) %>%
  filter(water_2011 == 0) %>%
  rename_with(~ str_remove(.x, "_2011"))

dat_2019 <- 
  cbind( fishnet, highwayPoints_fishnet_2019, fishnetPopulation19, lcRasters_2019, countyFishnet) %>%
  as.data.frame() %>%
  dplyr::select(uniqueID, development_change, lagDevelopment_2019, distance_highways_2019, pop_2019,  
                developed_2019, forest_2019, farm_2019, wetlands_2019, otherUndeveloped_2019, water_2019,
                NAME, geometry) %>%
  filter(water_2019 == 0)  %>%
  rename_with(~ str_remove(.x, "_2019"))
  

```

## 4.2 Feature Exploration

**Relationship between Variables and Outcome and Influence on Model:**
Before final model estimation, we explore the relationship between each predictor and the development outcome to understand how they might influence the model. Since our dependent variable (`development_change`) is binary (indicating whether a cell developed between 2011 and 2019) we examine how the mean value of each continuous variable differs between changed and unchanged cells.

We use bar plots to compare mean values of continuous predictors such as distance to highways, spatial lag of development, and population across the two outcome classes. These comparisons offer insight into whether features are likely to be strong predictors. For instance, we might find that developed cells tend to be closer to highways or have lower spatial lag values, reinforcing hypotheses about the role of accessibility.

```{r, warning = FALSE, message = FALSE}
dat_2011 %>%
  dplyr::select(distance_highways,lagDevelopment,development_change, pop) %>%
  gather(Variable, Value, -development_change) %>%
  ggplot(., aes(development_change, Value, fill=development_change)) + 
    geom_bar(position = "dodge", stat = "summary", fun.y = "mean") +
    facet_wrap(~Variable, scales = "free") +
    scale_fill_manual(values = palette2,
                      labels=c("No Change","New Development"),
                      name="Mean Value") +
    labs(title="New Development as a Function of Continuous Variables") +
    theme_minimal() 
```

**Relationship and Influence by Land Cover Type:**
Additionally, we evaluate development conversion rates across initial land cover types. This helps identify which landscapes (e.g., forest, farm, or wetlands) are more likely to transition to urban use. The results, presented in a table of conversion rates, reveal how land cover composition influences development likelihood.

These diagnostics validate our feature engineering efforts and provide a clearer picture of the forces driving change across the Charlotte MSA.

```{r, warning = FALSE, message = FALSE}
dat_2011 %>%
  dplyr::select(development_change, forest, farm, wetlands, otherUndeveloped) %>%
  gather(key = "Land_Cover_Type", Value, -development_change) %>%
     group_by(development_change, Land_Cover_Type) %>%
     summarize(n = sum(as.numeric(Value))) %>%
     ungroup() %>%
    mutate(Conversion_Rate = paste0(round(100 * n/sum(n), 2), "%")) %>%
    filter(development_change == 1) %>%
  dplyr::select(Land_Cover_Type,Conversion_Rate) %>%
  kable() %>% kable_styling(full_width = F)
```


# 5. Modeling
In this stage, we create models to predict where development is most likely to occur in the Charlotte MSA. Using logistic regression, we explore how well different combinations of predictors can estimate the binary outcome of land cover change (undeveloped to developed) between 2011 and 2018.

## 5.1 Splitting the Data

We divide our dataset into training and testing subsets using a 50/50 split to ensure a sufficient number of developed cells are included for model training. We stratify by land cover type to maintain balanced representation across categories.

```{r, warning = FALSE, message = FALSE}
set.seed(3456)
trainIndex <- 
  createDataPartition(dat_2011$otherUndeveloped, p = .50,
                                  list = FALSE,
                                  times = 1)
datTrain <- dat_2011[ trainIndex,]
datTest  <- dat_2011[-trainIndex,]

```

## 5.2 Model Specification

We construct six logistic regression models of increasing complexity. The models begin with only land cover types and sequentially add spatial lag, population density, county fixed effects, and highway accessibility. The final model introduces an interaction term between highway proximity and spatial lag to test whether the effect of one predictor depends on the other.


```{r, warning = FALSE, message = FALSE}
Model1 <- glm(development_change ~ wetlands + forest  + farm + 
                otherUndeveloped, 
              family="binomial"(link="logit"), data = datTrain)

Model2 <- glm(development_change ~ wetlands + forest  + farm + 
                otherUndeveloped + lagDevelopment, 
              family="binomial"(link="logit"), data = datTrain)
              
Model3 <- glm(development_change ~ wetlands + forest  + farm +
                otherUndeveloped + lagDevelopment + pop,
              family="binomial"(link="logit"), data = datTrain)          
              
Model4 <- glm(development_change ~ wetlands + forest  + farm + 
                otherUndeveloped + lagDevelopment + pop + NAME, 
              family="binomial"(link="logit"), data = datTrain) 

Model5 <- glm(development_change ~ wetlands + forest  + farm + 
                otherUndeveloped + lagDevelopment + pop + distance_highways + NAME, 
              family="binomial"(link="logit"), data = datTrain) 

Model6 <- glm(development_change ~ wetlands + forest  + farm + 
                otherUndeveloped + pop + lagDevelopment * distance_highways + NAME, 
              family="binomial"(link="logit"), data = datTrain) 
```



# ALERT ------- AUSTIN AND ABE REVIEW SLECTION OF **MODEL 6** AND CONFIRM IT IS BEST - AFFECTS 5.3 and 5.4 BELOW -- READ 12.2 IN MICHAELS RMD BEFORE SELECTING (I SPLIT 12.2 into two as 5.2 and 5.3)  ------- 



## 5.3 Model Comparison and AIC Evaluation

We **examine model summaries** and **compare Akaike Information Criterion (AIC) scores** to evaluate each modelâ€™s fit. While lower AIC values indicate better explanatory power, we ultimately select the model that balances accuracy, generalizability, and interpretability: **Model 6**.

**Summary for Model 6:**
```{r}

summary(Model6)

```

**Compare AIC Scores:**
```{r}
data.frame(
  Model = c("Model1", "Model2", "Model3", "Model4", "Model5", "Model6"),
  AIC = c(Model1$aic, Model2$aic, Model3$aic, Model4$aic, Model5$aic, Model6$aic)
) %>%
  ggplot()+
  geom_bar(aes(x = Model, y = AIC), stat = "identity")+
  theme_minimal()

```

## 5.4 Model Validation
### 5.4.1. Create Test Set
To evaluate the performance (forecasting/predictive accuracy) of our selected model **(Model 6)**, we start by applying the trained model onto the test dataset. The model returns predicted probabilities for each cell, indicating the likelihood of development for each cell from 2011 to 2019.

**Run Model on Test Set:**
```{r, warning = FALSE, message = FALSE}
testSetProbs <- 
  data.frame(class = datTest$development_change,
             probs = predict(Model6, datTest, type="response")) 
```
We created a new table that includes two things for each location: the actual outcome (whether the land developed or not) and the modelâ€™s estimated chance that it would develop. These chances are given as percentages, ranging from 0 (very unlikely) to 1 (very likely).

### 5.4.2. Examine Probability Distribution
We first examine the distribution of these predicted probabilities through a density plot, comparing the probability distributions for cells that developed and those that did not. This plot helps us identify an appropriate threshold to classify cells as 'predicted to develop' versus 'not predicted to develop'.

**Create Density Plot:**
```{r}  
ggplot(testSetProbs, aes(probs)) +
  geom_density(aes(fill=class), alpha=0.5) +
  scale_fill_manual(values = palette2,
                    labels=c("No Change","New Development")) +
  labs(title = "Histogram of test set predicted probabilities",
       x="Predicted Probabilities",y="Density") +
  theme_minimal()
```

### 5.4.3. Confusion Matrix
We then construct a confusion matrix using a 5% probability threshold, allowing us to quantify prediction accuracy in terms of true positives, false positives, true negatives, and false negatives. These diagnostics offer insight into how well the model distinguishes between the two classes.

**Create Confusion Matrix:**
```{r}
testSetProbs$predClass  = ifelse(testSetProbs$probs > .05 ,1,0)

caret::confusionMatrix(reference = as.factor(testSetProbs$class), 
                       data = as.factor(testSetProbs$predClass), 
                       positive = "1")

```

### 5.4.4. ROC Curve

Finally, we visualize model discrimination ability using a Receiver Operating Characteristic (ROC) curve. A ROC curve that bows well above the 45-degree baseline suggests strong model performance.

**Create ROC Curve:**
```{r roc_curve, message = FALSE, warning = FALSE}

ggplot(testSetProbs, aes(d = as.numeric(class), m = probs)) + 
  geom_roc(n.cuts = 50, labels = FALSE) + 
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  theme_minimal()
```

## 5.5. Analyze Prediction Errors

With our model trained and validated, we now assess its predictive accuracy across the full dataset for 2019, focusing on how different classification thresholds affect the modelâ€™s generalizability. Since most cells in the Charlotte MSA did not develop between 2011 and 2019, threshold selection plays a critical role in balancing sensitivity (correctly identifying change) and specificity (correctly identifying no change).

### 5.5.1 Set Thresholds and Create Predictions

We test two probability thresholds: 5% and 17%. A lower (5%) threshold captures more development (higher true positive rate) but also results in more false positives. A higher (17%) threshold is more conservative, predicting less change but increasing specificity. To compare performance, we generate predicted probabilities for each cell and then classify those probabilities using both thresholds. We also label the resulting prediction outcomes using categories like "True Positive" and "False Negative".

```{r, warning = FALSE, message = FALSE}
dat_2011_preds <-         
  dat_2011 %>%
    mutate(probs = predict(Model6, dat_2011, type="response")) %>%
   mutate(Threshold_5_Pct = as.factor(ifelse(probs >= 0.05 ,1,0)),
           Threshold_17_Pct =  as.factor(ifelse(probs >= 0.17 ,1,0))) %>%
  mutate(confResult_05 =case_when(Threshold_5_Pct == 0 & development_change == 0 ~ "True_Negative",
                              Threshold_5_Pct == 1 & development_change==1 ~ "True_Positive",
                              Threshold_5_Pct == 0 & development_change==1 ~ "False_Negative",
                              Threshold_5_Pct == 1 & development_change ==0 ~ "False_Positive")) %>%
  mutate(confResult_17 =case_when(Threshold_17_Pct == 0 & development_change == 0 ~ "True_Negative",
                              Threshold_17_Pct == 1 & development_change==1 ~ "True_Positive",
                              Threshold_17_Pct == 0 & development_change==1 ~ "False_Negative",
                              Threshold_17_Pct == 1 & development_change ==0 ~ "False_Positive")) %>%
  st_as_sf()
```

### 5.5.2 Evaluating Errors by County

Next, we summarize classification outcomes by county and threshold to examine how performance varies geographically. This helps identify counties where the model is over- or under-predicting development.

```{r}

# Summarize by county and model type
dat_2011_preds %>%
  as.data.frame() %>%
  dplyr::select(confResult_05, confResult_17, NAME) %>%
  pivot_longer(cols = starts_with("confResult"), names_to = "Model_Type", values_to = "Confusion_Result") %>%
  group_by(NAME, Model_Type, Confusion_Result) %>%
  tally() %>%
  pivot_wider(names_from = Confusion_Result, values_from = n, values_fill = 0) %>% # Reshape to wide format
  mutate(TN_Rate_Specificity = 100*( True_Negative/(True_Negative+False_Positive)),
         TP_Rate_Sensitivity = 100*( True_Positive/(True_Positive + False_Negative))) %>%
  dplyr::select(NAME, Model_Type, TN_Rate_Specificity, TP_Rate_Sensitivity) %>%
  kable() %>%
  kable_styling()

```

### 5.5.3 Mapping Prediction Outcomes

Finally, we visualize the spatial distribution of prediction errors for both thresholds across counties. These maps provide insight into which areas of the Charlotte MSA the model predicts more reliably and where further refinement may be needed.

**Map Development Prediction Accuracy (Errors) By Threshold:**
<div class="superbigimage">
```{r, warning = FALSE, message= FALSE, fig.height = 6, fig.width= 8}
ggplot() +
  geom_sf(data= dat_2011_preds %>%
            st_centroid() %>%
               dplyr::select(confResult_05, confResult_17, geometry) %>%
               gather(key = "Variable", value = "Value", -geometry), 
             aes(colour=Value)) +
  facet_wrap(~Variable) +
  scale_colour_manual(values = c("red", "yellow", "blue", "grey"), labels=c("False Negative","False Positive", "True Negative", "True Positive"),
                      name="") +
  labs(title="Development Predictions - By Threshold") + 
  theme_void()
```
</div>

These diagnostics reveal the practical implications of our model and support its use for guiding policy decisions in transportation planning and growth management.






# ALERT  ------- FOR ABE







# 6. Forcaseting

Having validated the accuracy of our model, we now apply it to generate a forecast for urban development in the Charlotte region for the year 2027. This forecast uses `t2` data (2019), incorporating the same variables used in training and also includes the updated ** ---------- ALERT distance-to-infrastructure ALERT ---------- ** layer reflecting the proposed new highway.

We use **Model 6**, our final logistic regression model, and apply a 17% classification threshold. This threshold was chosen based on our validation analysis, as it balances sensitivity (capturing new development) with specificity (limiting false positives).

**Create Shapefile:**
Generate a new spatial object where each cell is labeled with its forecasted development status by 2027. Predictions are based on the modeled probability of change, with values above 0.17 flagged as likely to develop.

```{r}
dat_2027_preds <- dat_2019 %>%
    mutate(probs = predict(Model6, dat_2019, type="response") ,
           Prediction = as.factor(ifelse(probs >= 0.17 ,1,0))) %>%
  st_as_sf()

```

**Visualize 2027 Predictions:**
Visualize the forecast using a spatial plot, identifying areas across Mecklenburg, Cabarrus, Gaston, and Union counties that are most at risk of development pressure from the propsed highway.

```{r, warning = FALSE, message = FALSE, fig.height= 8, fig.width= 8 }
ggplot(data=dat_2027_preds) +
  geom_point(aes(x=xyC(dat_2027_preds)[,1], 
                 y=xyC(dat_2027_preds)[,2], colour = Prediction)) +
  geom_sf(data = studyAreaCounties, fill = "transparent")+
  labs(title="Development Predictions, 2027") + 
  theme_void()
```
The resulting map displays the spatial distribution of expected development, providing a basis for planning decisions that prioritize infrastructure alignment, environmental protection, and equitable growth management.


# 7. Impact Assessment

With the 2028 development forecast complete, we now assess the scale and distribution of predicted growth across the Charlotte Metropolitan Area. This step is essential for planners to anticipate infrastructure needs, protect sensitive lands, and align policies with projected development demand.

We begin by calculating the total amount of land projected to convert from undeveloped to developed. The forecasted cells classified as '1' are multiplied by the raster resolution to estimate area in square meters, square kilometers, and square miles.

```{r}
dat_2027_preds %>%
  as.data.frame() %>%
  filter(Prediction == 1) %>%
  tally() %>%
  rename(total_cells = n) %>%
  mutate(total_area_m = total_cells * res(lc_2019_rs)[1],
         total_km2 = total_area_m/1000000,
         total_mi2 = total_km2*0.386102) %>%
  kable() %>%
  kable_styling ()

```

Next, we break down these results by county to explore how growth is likely to be distributed across Mecklenburg, Cabarrus, Gaston, and Union counties.

```{r}
dat_2027_preds %>%
  as.data.frame() %>%
  filter(Prediction == 1) %>%
  group_by(NAME) %>%
  tally() %>%
  rename(total_cells = n) %>%
  mutate(total_area_m = total_cells * res(lc_2019_rs)[1],
         total_km2 = total_area_m/1000000,
         total_mi2 = total_km2*0.386102) %>%
  kable() %>%
  kable_styling ()

```

Lastly, we evaluate development by existing land cover type to determine which land cover type areas are most at risk. This insight supports proactive land use planning and conservation.

```{r}
dat_2027_preds %>%
  as.data.frame() %>%
  filter(Prediction == 1) %>%
  dplyr::select(farm, otherUndeveloped, forest, wetlands, NAME) %>%
  gather(-NAME, key = "Variable", value = "Value") %>%
  group_by(NAME, Variable) %>%
  summarize(total_cells = sum(as.numeric(Value))) %>%
  mutate(total_area_m = total_cells * res(lc_2019_rs)[1],
         total_km2 = total_area_m/1000000,
         total_mi2 = total_km2*0.386102) %>%
  kable() %>%
  kable_styling ()

```

This impact assessment provides the quantitative foundation needed to interpret the spatial and environmental implications of forecasted development.












# 8. Next Steps: Toward an Allocation Strategy

Now that we have a spatially explicit forecast of likely development across the Charlotte MSA, the next phase is to develop a planning strategy to manage that growth. This involves aligning policy tools with predicted development pressure to guide growth toward desirable outcomes.

Here are a few ways you can build on this analysis:

- **Integrate with Population and Employment Projections**: Compare the total forecasted developed area with regional growth forecasts published by the local MPO or state agencies. Are the predicted areas adequate to accommodate projected demand?

- **Target Growth with Zoning Tools**: Use zoning overlays, such as upzoning in areas with high predicted development and existing infrastructure, to concentrate growth. TOD overlays around proposed transportation corridors could further amplify model-consistent growth.

- **Protect Sensitive Land**: Overlay the forecast map with conservation data layers (e.g., wetlands, floodplains, or habitat zones). Consider strategies such as conservation easements or transfer of development rights (TDR) to minimize encroachment.

- **Compare Alternate Scenarios**: Model additional infrastructure projects or policy interventions and re-run forecasts. Compare the outcomes to assess trade-offs in sprawl, equity, or environmental impact.

- **Quantify Fragmentation Risk**: Evaluate whether development patterns lead to fragmentation of open space or habitat corridors. Metrics such as patch size or proximity to intact landscapes can inform this analysis.

By pursuing these steps, planners can translate the raw forecast into a strategic plan that manages future development in a way that aligns with Charlotteâ€™s sustainability, equity, and growth management goals.












# 15. Next Steps - Towards an Allocation Strategy

What do you do after you have a geographically specific forecast of likely development? You can integrate it with population projection information to see if forecasted growth areas seem adequate to accommodate future growth. You can dive in on areas where sensitive lands are at risk and determine if upzoning in other areas of nearby development might accommodate that population. You can compare future scenarios for fragmentation effects. There are myriad possibilities.






#TO DO

## Confirm Using **Model 6** for Model Deployment and Interpretation
### Model results (summary), threshold selection, and validation (confusion matrix and exploration of errors)

## 2028 Forecast Results
### Assessment of impact - where is development likely to occur? Are sensitive lands at risk? Where?

## Recommendations for Charlotte MSA
### Key recommendations - use your planning expertise acquired through readings and lectures - give three key recommendations about growth allocation and management implications given the results of your forecast. This requires you to do some desk research about population and employment forecasts for your region (these are published by local MPOs) or about important local growth management issues.

## Conclusion
### A SUMMARY OF PROJECT???





# 16. Data Sources
- **Land Cover Data**: Multi-Resolution Land Characteristics (MRLC) Consortium â€“ [https://www.mrlc.gov/data?f%5B0%5D=category%3ALand%20Cover](https://www.mrlc.gov/data?f%5B0%5D=category%3ALand%20Cover)
- **Census Data**: United States Census Bureau â€“ [https://api.census.gov/data/key_signup.html](https://api.census.gov/data/key_signup.html)
- **Roads Data**: Data.gov, accessed using the `Tigris` R package â€“ [https://catalog.data.gov/dataset/tiger-line-shapefile-2023-state-north-carolina-primary-and-secondary-roads](https://catalog.data.gov/dataset/tiger-line-shapefile-2023-state-north-carolina-primary-and-secondary-roads)
- **County Boundaries**: North Carolina Department of Transportation â€“ [https://www.nconemap.gov/datasets/NCDOT::ncdot-county-boundaries/about](https://www.nconemap.gov/datasets/NCDOT::ncdot-county-boundaries/about)


# 17. Credits
This report is completed as an assignment for the University of Pennsylvania's Spring 2025 course, **CPLN 6750/MUSA 6750: Land Use and Environmental Modeling**, taught by **Michael Fichman** in the Department of City and Regional Planning at the Stuart Weitzman School of Design. This analysis was completed by **Abe Doroshow and Austin Studner (Sutherland)**. The workflow in this Urban Growth Model was created for the course by Michael Fichman, the late Prof. Ken Steif, and Jenna Epstein, and adapted and inspired from the California Urban Futures Model, developed by Prof. Emeritus John Landis. 
